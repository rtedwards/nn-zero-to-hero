{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rtedwards/nn-zero-to-hero/blob/main/notebooks/1_makemore_bigrams.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "ml1bw9uj2yEX"
      },
      "id": "ml1bw9uj2yEX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ea59c4c-9f47-4ac4-9859-42a0cb3897b4",
      "metadata": {
        "id": "7ea59c4c-9f47-4ac4-9859-42a0cb3897b4"
      },
      "outputs": [],
      "source": [
        "words = open(\"names.txt\", \"r\").read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0351dfd1-e8a5-417d-a230-38050dc094ec",
      "metadata": {
        "id": "0351dfd1-e8a5-417d-a230-38050dc094ec"
      },
      "outputs": [],
      "source": [
        "words[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f8a724-ec44-489b-827f-f442c0b3ee32",
      "metadata": {
        "id": "80f8a724-ec44-489b-827f-f442c0b3ee32"
      },
      "outputs": [],
      "source": [
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "863e8ddf-0a03-407f-bb57-21b48fa4852c",
      "metadata": {
        "id": "863e8ddf-0a03-407f-bb57-21b48fa4852c"
      },
      "outputs": [],
      "source": [
        "max(len(w) for w in words)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6dd5752-f686-4ab9-9b87-3e6091b26fef",
      "metadata": {
        "id": "f6dd5752-f686-4ab9-9b87-3e6091b26fef"
      },
      "source": [
        "## Bigram\n",
        "Given a character, we want to predict the next character in the sequence.  Always looking at the previous character to predict the next one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c8a847-e527-46b0-8a15-867b9b2bba7c",
      "metadata": {
        "id": "21c8a847-e527-46b0-8a15-867b9b2bba7c"
      },
      "outputs": [],
      "source": [
        "b = {}\n",
        "for w in words:\n",
        "    chs = [\"<S>\"] + list(w) + [\"<E>\"]\n",
        "    for ch1, ch2 in zip(chs, chs[1:]):\n",
        "        bigram = (ch1, ch2)\n",
        "        b[bigram] = b.get(bigram, 0) + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7703d05c-cc32-45c0-a3d3-065c18623be0",
      "metadata": {
        "scrolled": true,
        "id": "7703d05c-cc32-45c0-a3d3-065c18623be0"
      },
      "outputs": [],
      "source": [
        "sorted(b.items(), key=lambda kv: -kv[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c022924d-84da-4260-8ca8-b81693c8cde5",
      "metadata": {
        "id": "c022924d-84da-4260-8ca8-b81693c8cde5"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9b42e83-1899-4c6c-b551-5af14476924d",
      "metadata": {
        "id": "a9b42e83-1899-4c6c-b551-5af14476924d"
      },
      "outputs": [],
      "source": [
        "N = torch.zeros((27, 27), dtype=torch.int32) # 26 letters + <S> and <E>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d84fca-dc21-4cd1-9b22-f001791e5ce5",
      "metadata": {
        "id": "c9d84fca-dc21-4cd1-9b22-f001791e5ce5"
      },
      "outputs": [],
      "source": [
        "chars = sorted(list(set(\"\".join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi[\".\"] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ddd1c53-6eaa-4173-ac7f-dddb1667aae0",
      "metadata": {
        "id": "0ddd1c53-6eaa-4173-ac7f-dddb1667aae0"
      },
      "outputs": [],
      "source": [
        "for w in words:\n",
        "    chs = [\".\"] + list(w) + [\".\"]\n",
        "    for ch1, ch2 in zip(chs, chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        N[ix1, ix2] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78b73e2b-7923-4f09-bd4c-4a8bdae005b7",
      "metadata": {
        "id": "78b73e2b-7923-4f09-bd4c-4a8bdae005b7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(16,16))\n",
        "plt.imshow(N, cmap=\"Blues\")\n",
        "for i in range(27):\n",
        "    for j in range(27):\n",
        "        chstr = itos[i] + itos[j]\n",
        "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color=\"gray\")\n",
        "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color=\"gray\")\n",
        "plt.axis(\"off\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72721c97-1b05-4dd9-a814-2861dfcebc1c",
      "metadata": {
        "id": "72721c97-1b05-4dd9-a814-2861dfcebc1c"
      },
      "outputs": [],
      "source": [
        "N[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab8eec68-0f2c-4ad9-9edb-002654545cb3",
      "metadata": {
        "id": "ab8eec68-0f2c-4ad9-9edb-002654545cb3"
      },
      "outputs": [],
      "source": [
        "p = N[0].float()\n",
        "p = p / p.sum()\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1086a15-e642-4cfc-8f6b-60384bacdce2",
      "metadata": {
        "id": "c1086a15-e642-4cfc-8f6b-60384bacdce2"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "itos[ix]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df4d78e0-fdcb-4588-99fa-0f7c881b7f17",
      "metadata": {
        "id": "df4d78e0-fdcb-4588-99fa-0f7c881b7f17"
      },
      "outputs": [],
      "source": [
        "P = (N+1).float() # the '1' is model smoothing to remove infinite nll\n",
        "P /= P.sum(1, keepdim=True)\n",
        "P[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff2cc89b-26b2-431a-b516-f8ee87603c3a",
      "metadata": {
        "id": "ff2cc89b-26b2-431a-b516-f8ee87603c3a"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(10):\n",
        "    out = []\n",
        "    ix = 0\n",
        "    while True:\n",
        "        p = P[ix]\n",
        "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "\n",
        "        out.append(itos[ix])\n",
        "        if ix == 0: # end token '.'\n",
        "            break\n",
        "\n",
        "    print(\"\".join(out))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient-Based Model"
      ],
      "metadata": {
        "id": "DSwfUKuM3bOB"
      },
      "id": "DSwfUKuM3bOB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f0ece96-514d-4acd-8fbd-83d04fa76670",
      "metadata": {
        "id": "8f0ece96-514d-4acd-8fbd-83d04fa76670"
      },
      "outputs": [],
      "source": [
        "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
        "# equivalent to maximizing the log likelihood (because log is monotomic)\n",
        "# equivalent to minimizing the negative log likelihood\n",
        "# equivalent to minimizing the average negative log likelihood\n",
        "\n",
        "# likelihood = product of all probabilities\n",
        "# log(a*b*c) = log(a) + log(b) + log(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b50b041-6215-4446-9d09-bce7a61b08d4",
      "metadata": {
        "id": "8b50b041-6215-4446-9d09-bce7a61b08d4"
      },
      "outputs": [],
      "source": [
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "\n",
        "for w in [\"andrejq\"]: #words:\n",
        "    chs = [\".\"] + list(w) + [\".\"]\n",
        "    for ch1, ch2 in zip(chs, chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        N[ix1, ix2] += 1\n",
        "        prob = P[ix1, ix2]\n",
        "        logprob = torch.log(prob)\n",
        "        log_likelihood += logprob\n",
        "        n += 1\n",
        "        print(f\"{ch1}{ch2}: {prob:.4f} {logprob:.4f}\")\n",
        "\n",
        "print(f\"{log_likelihood=}\")\n",
        "nll = -log_likelihood\n",
        "print(f\"{nll=}\")\n",
        "print(f\"{nll/n}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c870c28d-8f1b-41eb-bd70-c1979201839d",
      "metadata": {
        "id": "c870c28d-8f1b-41eb-bd70-c1979201839d"
      },
      "outputs": [],
      "source": [
        "# create the training set of bigrams (x,y)\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words[:1]:\n",
        "    chs = [\".\"] + list(w) + [\".\"]\n",
        "    for ch1, ch2 in zip(chs, chs[1:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        print(ch1, ch2)\n",
        "        xs.append(ix1)\n",
        "        ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the training set of trigrams (x,y,z)\n",
        "xs, ys, zs = [], [], []\n",
        "\n",
        "for w in words[:1]:\n",
        "    chs = [\".\"] + list(w) + [\".\"]\n",
        "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "        ix1 = stoi[ch1]\n",
        "        ix2 = stoi[ch2]\n",
        "        ix3 = stoi[ch3]\n",
        "        print(ch1, ch2, ch3)\n",
        "        xs.append(ix1)\n",
        "        ys.append(ix2)\n",
        "        zs.append(ix3)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "zs = torch.tensor(zs)"
      ],
      "metadata": {
        "id": "yLJpDCs53gIE"
      },
      "id": "yLJpDCs53gIE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xenc = F.one_hot(xs, num_classes=27).float()\n",
        "xenc"
      ],
      "metadata": {
        "id": "1ZLTjFSh3gK8"
      },
      "id": "1ZLTjFSh3gK8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization of turned on bits in each OHE\n",
        "plt.imshow(xenc)"
      ],
      "metadata": {
        "id": "BbMBNTHm3gM8"
      },
      "id": "BbMBNTHm3gM8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.randn((27, 27))\n",
        "xenc @ W # matrix multiplication\n",
        "# (5, 27) @ (27, 27) -> (5, 27)"
      ],
      "metadata": {
        "id": "WYHKMqng3gPT"
      },
      "id": "WYHKMqng3gPT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(xenc @ W)[3, 13] # firing rate of 13th neuron on 3rd input"
      ],
      "metadata": {
        "id": "5yz5qtjF3lcW"
      },
      "id": "5yz5qtjF3lcW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(xenc[3] * W[:, 13]).sum()"
      ],
      "metadata": {
        "id": "kNmJ5qVD3lhC"
      },
      "id": "kNmJ5qVD3lhC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# interpret weights as log counts\n",
        "logits = xenc @ W     # log-counts\n",
        "counts = logits.exp() # equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True)"
      ],
      "metadata": {
        "id": "0SZXGh333ljn"
      },
      "id": "0SZXGh333ljn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs[0].sum()"
      ],
      "metadata": {
        "id": "TVyx-lBT3o8O"
      },
      "id": "TVyx-lBT3o8O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary"
      ],
      "metadata": {
        "id": "dRPL0zpf3qXk"
      },
      "id": "dRPL0zpf3qXk"
    },
    {
      "cell_type": "code",
      "source": [
        "xs"
      ],
      "metadata": {
        "id": "eCW_RycX3o-S"
      },
      "id": "eCW_RycX3o-S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ys"
      ],
      "metadata": {
        "id": "KzwFOK-53pBG"
      },
      "id": "KzwFOK-53pBG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly initialize 27 neurons' weights\n",
        "# each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27,27), generator=g)"
      ],
      "metadata": {
        "id": "yXucRnuf3pDe"
      },
      "id": "yXucRnuf3pDe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Pass\n",
        "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "logits = xenc @ W     # predict log-counts\n",
        "counts = logits.exp() # counts, equivalent to N\n",
        "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "# btw, last 2 lines here are together called a\" softmax\""
      ],
      "metadata": {
        "id": "jQ9umCaP3pGJ"
      },
      "id": "jQ9umCaP3pGJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Softmax Activation Function**\n",
        "\n",
        "a normalization function that outputs probabilites\n",
        "\n",
        "$$\n",
        "\\begin{alignat}{2}\n",
        "\\text{Output Layer}\n",
        "& \\longrightarrow\n",
        "\\text{Softmax Activation Function}\n",
        "&& \\longrightarrow\n",
        "\\text{Probabilities} \\\\\n",
        "\\begin{bmatrix}\n",
        "1.3 \\\\\n",
        "5.1 \\\\\n",
        "2.2 \\\\\n",
        "0.7 \\\\\n",
        "1.1\n",
        "\\end{bmatrix}\n",
        "& \\longrightarrow\n",
        "\\frac{e^{z_i}}{\\sum^K_{j=1} e^{z_j}}\n",
        "&& \\longrightarrow\n",
        "\\begin{bmatrix}\n",
        "0.02 \\\\\n",
        "0.90 \\\\\n",
        "0.05 \\\\\n",
        "0.01 \\\\\n",
        "0.02\n",
        "\\end{bmatrix}\n",
        "\\end{alignat}\n",
        "$$"
      ],
      "metadata": {
        "id": "CIiASXhG3vy-"
      },
      "id": "CIiASXhG3vy-"
    },
    {
      "cell_type": "code",
      "source": [
        "nlls = torch.zeros(5)\n",
        "for i in range(5):\n",
        "    # i-th bigram:\n",
        "    x = xs[i].item() # input character index\n",
        "    y = ys[i].item() # label character index\n",
        "    print(\"--------\")\n",
        "    print(f\"bigram example {i+1}: '{itos[x]}{itos[y]}' (indexes {x},{y})\")\n",
        "    print(f\"input to the neural net: {x}\")\n",
        "    print(f\"output probabilities from the neural net:\", probs[i])\n",
        "    print(f\"label (actual next character): {y} ({itos[y]})\")\n",
        "    p = probs[i, y]\n",
        "    logp = torch.log(p)\n",
        "    nll = -logp\n",
        "    nlls[i] = nll\n",
        "    print(f\"probability assigned by the net to the correct character: {p.item()}\")\n",
        "    print(f\"log-likelihood: {logp.item()}\")\n",
        "    print(f\"negative log-likelihood: {nll.item()}\")\n",
        "\n",
        "\n",
        "print(\"========\")\n",
        "print(f\"average negative log-likelihood, i.e. loss = {nlls.mean().item()}\")"
      ],
      "metadata": {
        "id": "Xp5iUf1e3pIZ"
      },
      "id": "Xp5iUf1e3pIZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Full Model"
      ],
      "metadata": {
        "id": "HI9tuSrK3zo2"
      },
      "id": "HI9tuSrK3zo2"
    },
    {
      "cell_type": "code",
      "source": [
        "# create the training set of bigrams (x,y)\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)\n",
        "\n",
        "# randomly initialize 27 neurons' weights\n",
        "# each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)\n",
        "\n",
        "for k in tqdm(range(1000)):\n",
        "    # Forward Pass\n",
        "    xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "    logits = xenc @ W     # predict log-counts\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "    loss = -probs[torch.arange(num), ys].log().mean() # selects probabilities the net assigned to next characters\n",
        "    loss = loss + 0.01 * (W**2).mean() # loss\n",
        "\n",
        "    # Backward Pass\n",
        "    W.grad = None # more efficient than zeroing\n",
        "    loss.backward() # fills in intermediant gradients\n",
        "\n",
        "    # Update\n",
        "    W.data += -50 * W.grad\n",
        "\n",
        "    # print(f\"Loss: {loss.item()}\")\n",
        "\n",
        "print(f\"Loss: {loss.sum()}\")"
      ],
      "metadata": {
        "id": "W2SeQTvY3pK9"
      },
      "id": "W2SeQTvY3pK9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "L2kfXti032y0"
      },
      "id": "L2kfXti032y0"
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(20):\n",
        "    out = []\n",
        "    ix = 0\n",
        "    while True:\n",
        "        # --- Before ---\n",
        "        # p = P[ix]\n",
        "        # --- Now ---\n",
        "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
        "        logits = xenc @ W # predict log-counts\n",
        "        counts = logits.exp() # counts, equivalent to N\n",
        "        p = counts / counts.sum(1, keepdims=True)\n",
        "\n",
        "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "        out.append(itos[ix])\n",
        "        if ix == 0: # if end of word '.'\n",
        "            break\n",
        "    print(\"\".join(out))"
      ],
      "metadata": {
        "id": "uFl3lFf533k5"
      },
      "id": "uFl3lFf533k5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}