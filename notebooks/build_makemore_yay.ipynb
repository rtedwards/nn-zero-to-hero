{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea59c4c-9f47-4ac4-9859-42a0cb3897b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open(\"names.txt\", \"r\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0351dfd1-e8a5-417d-a230-38050dc094ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8a724-ec44-489b-827f-f442c0b3ee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863e8ddf-0a03-407f-bb57-21b48fa4852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(len(w) for w in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd5752-f686-4ab9-9b87-3e6091b26fef",
   "metadata": {},
   "source": [
    "## Bigram\n",
    "Given a character, we want to predict the next character in the sequence.  Always looking at the previous character to predict the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c8a847-e527-46b0-8a15-867b9b2bba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {}\n",
    "for w in words:\n",
    "    chs = [\"<S>\"] + list(w) + [\"<E>\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = (ch1, ch2)\n",
    "        b[bigram] = b.get(bigram, 0) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7703d05c-cc32-45c0-a3d3-065c18623be0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(b.items(), key=lambda kv: -kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022924d-84da-4260-8ca8-b81693c8cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b42e83-1899-4c6c-b551-5af14476924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27), dtype=torch.int32) # 26 letters + <S> and <E>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d84fca-dc21-4cd1-9b22-f001791e5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(\"\".join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd1c53-6eaa-4173-ac7f-dddb1667aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b73e2b-7923-4f09-bd4c-4a8bdae005b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap=\"Blues\")\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color=\"gray\")\n",
    "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color=\"gray\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72721c97-1b05-4dd9-a814-2861dfcebc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8eec68-0f2c-4ad9-9edb-002654545cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = N[0].float()\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1086a15-e642-4cfc-8f6b-60384bacdce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "itos[ix]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d78e0-fdcb-4588-99fa-0f7c881b7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = (N+1).float() # the '1' is model smoothing to remove infinite nll\n",
    "P /= P.sum(1, keepdim=True)\n",
    "P[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2cc89b-26b2-431a-b516-f8ee87603c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        p = P[ix]\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    \n",
    "        out.append(itos[ix])\n",
    "        if ix == 0: # end token '.'\n",
    "            break\n",
    "\n",
    "    print(\"\".join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ece96-514d-4acd-8fbd-83d04fa76670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOAL: maximize likelihood of the data w.r.t. model parameters (statistical modeling)\n",
    "# equivalent to maximizing the log likelihood (because log is monotomic)\n",
    "# equivalent to minimizing the negative log likelihood\n",
    "# equivalent to minimizing the average negative log likelihood\n",
    "\n",
    "# likelihood = product of all probabilities\n",
    "# log(a*b*c) = log(a) + log(b) + log(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b50b041-6215-4446-9d09-bce7a61b08d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = 0.0\n",
    "n = 0\n",
    "\n",
    "for w in [\"andrejq\"]: #words:\n",
    "    chs = [\".\"] + list(w) + [\".\"]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1\n",
    "        prob = P[ix1, ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n += 1\n",
    "        print(f\"{ch1}{ch2}: {prob:.4f} {logprob:.4f}\")\n",
    "\n",
    "print(f\"{log_likelihood=}\")\n",
    "nll = -log_likelihood\n",
    "print(f\"{nll=}\")\n",
    "print(f\"{nll/n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870c28d-8f1b-41eb-bd70-c1979201839d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
